{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copia di MODNet - WebCam-Based Video Matting Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he2gSkd1_Hab"
      },
      "source": [
        "# MODNet - WebCam-Based Portrait Video Matting Demo\r\n",
        "\r\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/pdf/2011.11961.pdf)          [![GitHub stars](https://img.shields.io/github/stars/ZHKKKe/MODNet?style=social)](https://github.com/ZHKKKe/MODNet)\r\n",
        "\r\n",
        "<p align=\"justify\">This is a <b>WebCam-Based Portrait Video Matting Demo</b> of our paper ''<a href=\"https://arxiv.org/pdf/2011.11961.pdf\">Is a Green Screen Really Necessary for Real-Time Portrait Matting?</a>''. We propose a trimap-free MODNet for portrait matting in real time (on a single GPU). If you want to perform matting for portrait images, please refer to our <b>Portrait Image Matting Demo</b> [<a href=\"https://colab.research.google.com/drive/1GANpbKT06aEFiW-Ssx0DQnnEADcXwQG6?usp=sharing\">colab</a>].\r\n",
        "\r\n",
        "<!-- <img src=\"https://raw.githubusercontent.com/ZHKKKe/MODNet/develop/doc/gif/image_matting_demo.gif\" width=\"40%\"> -->\r\n",
        "\r\n",
        "<p align=\"justify\"> We use ~400 unlabeled video clips (divided into ~50,000 unlabeled frames) downloaded from the internet to perform SOC to adapt MODNet to the video domain. Nonetheless, <b><font color='#FF000'>due to insufficient labeled training data (~3k labeled foregrounds), our model may still make errors in portrait semantics estimation under challenging scenes</font></b>.\r\n",
        "\r\n",
        "Please run the code step by step to call your WebCam for real-time portrait video matting. \r\n",
        "Note that <b><font color='#FF000'>due to Colab resource limitations, the fps of this demo is very low</font></b> (It is also based on your network status). If you have an Ubuntu system with WebCam, please consider trying our <a href=\"https://github.com/ZHKKKe/MODNet/tree/master/demo/video_matting\">offline demo</a> to get a higher <i>fps</i>. \r\n",
        "\r\n",
        "For a better experience, please:\r\n",
        "\r\n",
        "*   use a supported browser (Google Chrome is recommended) and allow third-party cookies (used to call WebCam)\r\n",
        "*   make sure the network is in good condition\r\n",
        "*   make sure the portrait and background are distinguishable, <i>i.e.</i>, are not similar\r\n",
        "*   run in soft and bright ambient lighting\r\n",
        "*   do not be too close or too far from the WebCam\r\n",
        "*   do not move too fast\r\n",
        "\r\n",
        "By the way, if you have any suggestions on improving the efficiency of executing JS scripts in Colab, <i>i.e.</i>, to make this demo have a higher <i>fps</i>, please let me know. Thanks in advance!\r\n",
        "</p>\r\n",
        "\r\n",
        "### **Let's start!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4qPYwklGk2b"
      },
      "source": [
        "## 1. Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEeBUunUHAnp"
      },
      "source": [
        "<p align=\"justify\">In the top menu of this session, select <b>Runtime -> Change runtime type</b>, and set <b>Hardware Accelerator</b> to <b>GPU</b>.</p>\r\n",
        "\r\n",
        "<p align=\"justify\">Clone the repository, and download the pre-trained model:</p>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQuJjy_UKpvW"
      },
      "source": [
        "import os\n",
        "\n",
        "# clone the repository\n",
        "%cd /content\n",
        "if not os.path.exists('MODNet'):\n",
        "  !git clone https://github.com/ZHKKKe/MODNet\n",
        "%cd MODNet/\n",
        "\n",
        "# dowload the pre-trained ckpt for video matting\n",
        "pretrained_ckpt = 'pretrained/modnet_webcam_portrait_matting.ckpt'\n",
        "if not os.path.exists(pretrained_ckpt):\n",
        "  !gdown --id 1Nf1ZxeJZJL8Qx9KadcYYyEmmlKhTADxX \\\n",
        "          -O pretrained/modnet_webcam_portrait_matting.ckpt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GftrpmnoHGCV"
      },
      "source": [
        "Define JS script to call WebCam:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prBcl0v0KvR2"
      },
      "source": [
        "import io\n",
        "import base64\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "\n",
        "def prepare_webcam():\n",
        "  display(\n",
        "    Javascript('''\n",
        "      var div = null;\n",
        "      var video;\n",
        "      var stream;\n",
        "      var imgElement;\n",
        "      var captureCanvas;\n",
        "      var pendingResolve = null;\n",
        "      \n",
        "      async function onAnimationFrame() {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "        if (pendingResolve) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          var result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
        "\n",
        "          var lp = pendingResolve;\n",
        "          pendingResolve = null;\n",
        "          lp(result);\n",
        "        }\n",
        "      }\n",
        "      \n",
        "      async function initWebCam() {\n",
        "        div = document.createElement('div');\n",
        "        document.body.appendChild(div);\n",
        "            \n",
        "        video = document.createElement('video');\n",
        "        video.style.display = 'inline-block';\n",
        "        stream = await navigator.mediaDevices.getUserMedia(\n",
        "            {video: { facingMode: \"environment\"}});\n",
        "        div.appendChild(video);\n",
        "\n",
        "        imgElement = document.createElement('img');\n",
        "        imgElement.style.display = 'inline-block';\n",
        "        div.appendChild(imgElement);\n",
        "        \n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        captureCanvas = document.createElement('canvas');\n",
        "        captureCanvas.width = 640;\n",
        "        captureCanvas.height = 480;\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "        \n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      async function processFrame(fgFrame) {\n",
        "        if (div == null) {\n",
        "          stream = await initWebCam();\n",
        "        }\n",
        "\n",
        "        if (fgFrame != \"\") {\n",
        "          var videoRect = video.getClientRects()[0];\n",
        "          imgElement.style.top = videoRect.top + \"px\";\n",
        "          imgElement.style.left = videoRect.left + \"px\";\n",
        "          imgElement.style.width = videoRect.width + \"px\";\n",
        "          imgElement.style.height = videoRect.height + \"px\";\n",
        "          imgElement.src = fgFrame;\n",
        "        }\n",
        "\n",
        "        return await new Promise(\n",
        "          function(resolve, reject) {pendingResolve = resolve;});\n",
        "      }\n",
        "    ''')\n",
        "  )\n",
        "    \n",
        "def process_frame(fg_frame):\n",
        "  return eval_js('processFrame(\"{}\")'.format(fg_frame))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nze8eWbfHaoF"
      },
      "source": [
        "Load the pre-trained MODNet and define the inference code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pmCZ-kt4dU-"
      },
      "source": [
        "import io\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from src.models.modnet import MODNet\n",
        "\n",
        "\n",
        "modnet = MODNet(backbone_pretrained=False)\n",
        "modnet = nn.DataParallel(modnet).cuda()\n",
        "modnet.load_state_dict(torch.load(pretrained_ckpt))\n",
        "modnet.eval()\n",
        "\n",
        "\n",
        "torch_transforms = transforms.Compose(\n",
        "  [\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "def modnet_matting(modnet, im_frame):\n",
        "  im_bytes = base64.b64decode(im_frame.split(',')[1])\n",
        "  im_PIL = PIL.Image.open(io.BytesIO(im_bytes))\n",
        "  im_np = np.asarray(im_PIL)\n",
        "\n",
        "  im_tensor = torch_transforms(im_PIL)\n",
        "  im_tensor = im_tensor[None, :, :, :].cuda()\n",
        "  \n",
        "  _, _, matte_tensor = modnet(im_tensor, True)\n",
        "  matte_tensor = matte_tensor.repeat(1, 3, 1, 1)\n",
        "  matte_np = matte_tensor[0].data.cpu().numpy().transpose(1, 2, 0)\n",
        "  fg_np = matte_np * im_np + (1 - matte_np) * np.full(im_np.shape, 255.0)\n",
        "  fg_PIL = PIL.Image.fromarray(np.uint8(fg_np))\n",
        "\n",
        "  io_buffer = io.BytesIO()\n",
        "  fg_PIL.save(io_buffer, format='jpeg')\n",
        "  fg_frame = 'data:image/jpeg;base64,{}'.format(\n",
        "      (str(base64.b64encode(io_buffer.getvalue()), 'utf-8')))\n",
        "  return fg_frame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdYVB5CiJnS7"
      },
      "source": [
        "## 2. Run Video Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ3B7Wbv4f_x"
      },
      "source": [
        "# prepare WebCam\n",
        "prepare_webcam()\n",
        "\n",
        "# main loop\n",
        "fg_frame = ''\n",
        "while True:\n",
        "  # show the processed frame and capture a new frame\n",
        "  # TODO: this step is very slow!\n",
        "  frame = process_frame(fg_frame)\n",
        "  # matting by MODNet\n",
        "  # NOTE: matting inference is fast\n",
        "  fg_frame = modnet_matting(modnet, frame)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}